{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ca8ea407-817d-452e-ae64-3bdc3fa2026d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv,find_dotenv\n",
    "from langchain_core.prompts import PromptTemplate,ChatPromptTemplate\n",
    "from langchain_core.messages import SystemMessage,HumanMessage,AIMessage\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.prompts import SystemMessagePromptTemplate,HumanMessagePromptTemplate\n",
    "\n",
    "from langchain_core.example_selectors import MaxMarginalRelevanceExampleSelector,SemanticSimilarityExampleSelector\n",
    "from langchain.prompts import PromptTemplate,FewShotPromptTemplate\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain.embeddings import SentenceTransformerEmbeddings\n",
    "from langchain.vectorstores import FAISS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b75db88f-c9d0-489a-ab9d-18a54907593c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv(dotenv_path=find_dotenv(filename=\"../.env\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c64c9d23-96be-4746-b2ee-91341a4f49e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "llmGemini=ChatGoogleGenerativeAI(model=\"gemini-2.0-flash-001\")\n",
    "llmOpenAI=ChatOpenAI(model=\"gpt-3.5-turbo\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3a4a5146-7e52-45f1-8b0a-a09e820eacef",
   "metadata": {},
   "outputs": [],
   "source": [
    "examples=[\n",
    "    {\"input\":\"happy\",\"output\":\"sad\"},\n",
    "    {\"input\":\"tall\",\"output\":\"short\"},\n",
    "    {\"input\": \"energetic\", \"output\": \"lethargic\"},\n",
    "    {\"input\": \"sunny\", \"output\": \"gloomy\"},\n",
    "    {\"input\": \"windy\", \"output\": \"calm\"},\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "414c11fd-f28b-4871-8f21-5d08ccb26c93",
   "metadata": {},
   "outputs": [],
   "source": [
    "examplePrompt=PromptTemplate(\n",
    "    input_variables=[\"input\",\"output\"],\n",
    "    # The input and output are the input and output in the examples which gets mapped to the value of the input\n",
    "    # So the format will be: \"Input: sunny\\n Output: gloomy\n",
    "    template=\"Input: {input}\\n Output:{output}\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54bfcee6-11bb-4afe-bcf6-60f8299c663b",
   "metadata": {},
   "source": [
    "<h3>The MaxMarginalRelevanceExampleSelector selects examples based on a combination of which examples are most similar to the inputs, while also optimizing for Diversity. It does this by finding the examples with the embeddings that have the greatest cosine similarity with the inputs, and then iteratively adding them while penalizing them for closeness to already selected examples</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b9914ed1-400d-4661-b288-03cf21f0e45c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MSI\\AppData\\Local\\Temp\\ipykernel_15092\\248197981.py:3: LangChainDeprecationWarning: Default values for HuggingFaceEmbeddings.model_name were deprecated in LangChain 0.2.16 and will be removed in 0.4.0. Explicitly pass a model_name to the HuggingFaceEmbeddings constructor instead.\n",
      "  embeddings=SentenceTransformerEmbeddings(),\n"
     ]
    }
   ],
   "source": [
    "exampleSelector=MaxMarginalRelevanceExampleSelector.from_examples(\n",
    "    examples=examples,\n",
    "    embeddings=SentenceTransformerEmbeddings(),\n",
    "    vectorstore_cls=FAISS,\n",
    "    k=2,  # Number of examples to select\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2e1cecd6-67d8-4b2d-a15b-8936b05f8523",
   "metadata": {},
   "outputs": [],
   "source": [
    "mmrPrompt=FewShotPromptTemplate(example_selector=exampleSelector,\n",
    "                                prefix=\"Give the Antonym for every input\",\n",
    "                                example_prompt=examplePrompt,\n",
    "                                suffix=\"Input Adjective: {adjective}\\nAntonym: \",\n",
    "                                input_variables=['adjective']\n",
    "                               )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "87fa778a-1a05-48e7-9d22-c7320438fc22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Give the Antonym for every input\n",
      "\n",
      "Input: happy\n",
      " Output:sad\n",
      "\n",
      "Input: energetic\n",
      " Output:lethargic\n",
      "\n",
      "Input Adjective: worried\n",
      "Antonym: \n"
     ]
    }
   ],
   "source": [
    "print(mmrPrompt.format(adjective=\"worried\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6b3f456c-187d-43a3-b6c1-f2527a38b286",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain=RunnablePassthrough()|mmrPrompt|llmGemini|StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9ca3c8d0-f87a-4186-87c7-45b7f458019d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Antonym: Tidy\n"
     ]
    }
   ],
   "source": [
    "print(chain.invoke(input={\"adjective\":\"Untidy\"}))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd55075a-87d9-4472-82b1-4dfc700bd633",
   "metadata": {},
   "source": [
    "<h3>Semantic Similarity Example Selector</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "99f8a546-1b8e-4083-b667-d500190a2101",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MSI\\AppData\\Local\\Temp\\ipykernel_15092\\319744806.py:3: LangChainDeprecationWarning: Default values for HuggingFaceEmbeddings.model_name were deprecated in LangChain 0.2.16 and will be removed in 0.4.0. Explicitly pass a model_name to the HuggingFaceEmbeddings constructor instead.\n",
      "  embeddings=SentenceTransformerEmbeddings(),\n"
     ]
    }
   ],
   "source": [
    "exampleSelector=SemanticSimilarityExampleSelector.from_examples(\n",
    "    examples=examples,\n",
    "    embeddings=SentenceTransformerEmbeddings(),\n",
    "    vectorstore_cls=FAISS,\n",
    "    k=2,  # Number of examples to select\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8356c116-55c2-4c84-b3f4-700033fc754c",
   "metadata": {},
   "outputs": [],
   "source": [
    "similarPrompt=FewShotPromptTemplate(example_selector=exampleSelector,\n",
    "                                prefix=\"Give the Antonym for every input\",\n",
    "                                example_prompt=examplePrompt,\n",
    "                                suffix=\"Input Adjective: {adjective}\\nAntonym: \",\n",
    "                                input_variables=['adjective']\n",
    "                               )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6f024c9b-d70c-46df-b275-bcda028a016b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Give the Antonym for every input\n",
      "\n",
      "Input: happy\n",
      " Output:sad\n",
      "\n",
      "Input: windy\n",
      " Output:calm\n",
      "\n",
      "Input Adjective: worried\n",
      "Antonym: \n"
     ]
    }
   ],
   "source": [
    "print(similarPrompt.format(adjective=\"worried\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8dc05259-601e-4da9-bac4-86c64e2ec88f",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain=RunnablePassthrough()|similarPrompt|llmGemini|StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "12714057-a5a0-4929-bacb-97463dc86ffd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Antonym: Tidy\n"
     ]
    }
   ],
   "source": [
    "print(chain.invoke(input={\"adjective\":\"Untidy\"}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ea5a702-bfcc-4242-9702-e8dceeeaf0ad",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lcnenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
